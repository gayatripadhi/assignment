This article demonstrates a very effective approach for face recognition when the dataset is very limited. Using only one image per person (one-shot learning), we managed to create a highly accurate model for recognizing company employees in real-time.
Convolutional Neural Networks (CNNs) have taken the computer vision community by storm, significantly surpassing the state-of-the-art techniques in many applications. One of the most important ingredients for success of such methods is the availability of training data. The annual ImageNet Large Scale Visual Recognition Challenge (ILSVRC) competition, active since 2010, was instrumental in providing data for general image classification tasks. The ILSVRC2017 image dataset contains approximately two million images, having two separate datasets for object localization and object detection. More recently, other researches have also made datasets available for scene classification and image segmentation.
However, in the world of face recognition, large scale public datasets have been lacking, and largely due to this factor, most of the recent advances in the community remain restricted to Internet giants such as Facebook and Google. For example, the most recent face recognition method by Google was trained using 260 million images. The size of this dataset is almost three orders of magnitude larger than any publicly available face dataset. Needless to say, building a dataset this large is beyond the capabilities of most research groups, particularly in academia.

Despite the lack of collaboration from the giants like Google and Facebook, many researchers around the world make great efforts in collecting new public datasets for face recognition. Such popular datasets are: CASIA-WebFace, VGGFace2, LFW and CelebFaces. A dozen of publicly available datasets consisting of more than 500K faces and 10K classes gave ML enthusiasts the opportunity to actually implement state-of-the-art algorithms. Moreover, being able to train the model also means being able to share it as a pretrained network by saving all weights after the training phase.
Siamese Networks and FaceNet
Having to work with a small dataset (one image per class, 440 classes) greatly limits the number of applicable techniques. It seems that the standard CNNs have big problems with one-shot learning tasks, mainly because of:
Standard CNNs work phenomenally when they are fed large amounts of data. However, they cannot find patterns specific to a certain class if there is not enough training data for that class.
It is certainly not convenient to retrain the model every time we add a picture of a new person to the system. Training CNNs takes a lot of computational power and time. So if we want to recognize employees, we do not want to train a new network every time we have a new employee, or if someone leaves the company.
One of the best deep learning architectures that work great with one-shot learning is called Siamese Network. The idea is quite simple:
Take an input and extract its embedding (mapping to a vector of continuous numbers) by passing it through a neural network.
Repeat step 1 with a different input.
Compare the two embeddings to check whether there is a similarity between the two data points. These two embeddings act as a latent feature representation of the data. In our case, images with the same person should have similar embeddings.
